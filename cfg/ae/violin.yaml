# pytorch_lightning==1.9.4
seed_everything: 2434
trainer:
  max_epochs: 600
  max_steps: 1470000 # 1000000, 1470000/2442=600
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 2
  gradient_clip_val: 0.5
  strategy: auto
  accelerator: gpu #gpu #cpu
  devices: 1
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_last: true
        monitor: val_loss
        save_on_train_epoch_end: false
        filename: "{epoch}-{step}-{val_loss:.3f}"
        save_top_k: 3
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_loss #train_loss  
        patience: 5 # 20*2 (check_val_every_n_epoch)=100epochs/check, 2000 * 2
        mode: min
        check_finite: true
        check_on_train_epoch_end: false #true
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      entity: lucien #wanghh # Changed to your account
      project: ddsp-violin-hmag-inharm # ddsp-violin-hmag-inharm, ddsp-violin-hmag, ddsp-violin-inharm, ddsp-violin-baseline
      log_model: 'all' # false, true, 'all'
model:
  class_path: ltng.ae.VoiceAutoEncoder
  init_args:
    # Set additional inputs: use_hmag_embedding, use_inharmonicity
    use_hmag_embedding: true
    use_inharmonicity: true
    encoder_class_path: models.enc.VocoderParameterEncoderInterface
    encoder_init_args:
      f0_min: 150 # Replace 196, 196 - 150 = 46 Hz (about 24% margin), violin and vocal ranges are different, see wav2f0.py
      f0_max: 4000 # Replace 1000, 3520 (E7) + 480 Hz (about 14% margin)
      backbone_type: models.unet.UNetEncoder
      n_fft: 1024
      hop_length: 240
      channels:
        - 32
        - 64
        - 128
        - 256
      strides:
        - 4
        - 4
        - 4
        - 4
      lstm_hidden_size: 256
      num_layers: 3
      dropout: 0.1
      learn_voicing: false
      learn_f0: false
    decoder: null
    criterion:
      class_path: loss.spec.MSSLoss
      init_args:
        n_ffts:
          - 509
          - 1021
          - 2053
        alpha: 1.0
        window: hanning
        center: true
    sample_rate: 24000
    voicing_loss_weight: 1.0
    f0_loss_weight: 1.0
    detach_voicing: true
    detach_f0: true
    train_with_true_f0: true
ckpt_path: null
data:
  class_path: ltng.data.ViolinEtudes
  init_args:
    # Set use_hmag_embedding for both model and data
    use_hmag_embedding: true
    batch_size: 64 # 128 for lr 0.0002; 256 for lr 0.0003 or 0.0004, batch_size and lr need linear relationship
    wav_dir: /root/violin_etudes_with_hmag_f0_labelling/
    duration: 2.0
    overlap: 1.5
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.0001

